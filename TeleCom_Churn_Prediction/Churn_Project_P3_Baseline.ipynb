{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Building \n",
    "We are going to build a set of models and estimate their quality. The solution must be simple, it will be our baseline solution. Baseline is necessary because allows:\n",
    "- Understand the approximate quality of a simple solution. Here we will apply mostly tested tools \n",
    "- Understand what type of model is better suitable for the task \n",
    "- Estimate the effectiveness of different data transformations \n",
    "\n",
    "As a baseline models we will use:\n",
    "- Linear model (e.g. `sklearn.linear_model.RidgeClassifier`)\n",
    "- Tree model (e.g. `sklearn.ensemble.RandomForestClassifier`)\n",
    "- Boosting Model (e.g. `sklearn.ensemble.GradientBoostingClassifier`)\n",
    "\n",
    "We are going to use the same dataset but this time from Kaggle. The dataset will become less (18.3k observations and 10k observations for testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "\n",
    "from tqdm.notebook import tqdm as log_progress\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Var1</th>\n",
       "      <th>Var2</th>\n",
       "      <th>Var3</th>\n",
       "      <th>Var4</th>\n",
       "      <th>Var5</th>\n",
       "      <th>Var6</th>\n",
       "      <th>Var7</th>\n",
       "      <th>Var8</th>\n",
       "      <th>Var9</th>\n",
       "      <th>...</th>\n",
       "      <th>Var222</th>\n",
       "      <th>Var223</th>\n",
       "      <th>Var224</th>\n",
       "      <th>Var225</th>\n",
       "      <th>Var226</th>\n",
       "      <th>Var227</th>\n",
       "      <th>Var228</th>\n",
       "      <th>Var229</th>\n",
       "      <th>Var230</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3052.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>vr93T2a</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fKCe</td>\n",
       "      <td>02N6s8f</td>\n",
       "      <td>xwM2aC7IdeMC0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1813.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>6hQ9lNX</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ELof</td>\n",
       "      <td>xb3V</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>55YFVY9</td>\n",
       "      <td>mj86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1953.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>catzS2D</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FSa2</td>\n",
       "      <td>ZI9m</td>\n",
       "      <td>ib5G6X1eUxUn6</td>\n",
       "      <td>mj86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1533.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>e4lqvY0</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>xb3V</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>686.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>MAz3HNj</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WqMG</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18294</th>\n",
       "      <td>18294</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>462.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>mErwEWL</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>uWr3</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18295</th>\n",
       "      <td>18295</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1603.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>catzS2D</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kG3k</td>\n",
       "      <td>uWr3</td>\n",
       "      <td>ZI9m</td>\n",
       "      <td>ib5G6X1eUxUn6</td>\n",
       "      <td>am7c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18296</th>\n",
       "      <td>18296</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1239.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>catzS2D</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ELof</td>\n",
       "      <td>Qcbd</td>\n",
       "      <td>ZI9m</td>\n",
       "      <td>55YFVY9</td>\n",
       "      <td>am7c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18297</th>\n",
       "      <td>18297</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>210.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>wg_DmEs</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WqMG</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18298</th>\n",
       "      <td>18298</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>343.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18299 rows Ã— 232 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  Var1  Var2  Var3  Var4  Var5    Var6  Var7  Var8  Var9  ...  \\\n",
       "0          0   NaN   NaN   NaN   NaN   NaN  3052.0   NaN   NaN   NaN  ...   \n",
       "1          1   NaN   NaN   NaN   NaN   NaN  1813.0   7.0   NaN   NaN  ...   \n",
       "2          2   NaN   NaN   NaN   NaN   NaN  1953.0   7.0   NaN   NaN  ...   \n",
       "3          3   NaN   NaN   NaN   NaN   NaN  1533.0   7.0   NaN   NaN  ...   \n",
       "4          4   NaN   NaN   NaN   NaN   NaN   686.0   7.0   NaN   NaN  ...   \n",
       "...      ...   ...   ...   ...   ...   ...     ...   ...   ...   ...  ...   \n",
       "18294  18294   NaN   NaN   NaN   NaN   NaN   462.0   0.0   NaN   NaN  ...   \n",
       "18295  18295   NaN   NaN   NaN   NaN   NaN  1603.0   7.0   NaN   NaN  ...   \n",
       "18296  18296   NaN   NaN   NaN   NaN   NaN  1239.0   7.0   NaN   NaN  ...   \n",
       "18297  18297   NaN   NaN   NaN   NaN   NaN   210.0   0.0   NaN   NaN  ...   \n",
       "18298  18298   NaN   NaN   NaN   NaN   NaN   343.0   0.0   NaN   NaN  ...   \n",
       "\n",
       "        Var222      Var223  Var224  Var225  Var226   Var227         Var228  \\\n",
       "0      vr93T2a  LM8l689qOp     NaN     NaN    fKCe  02N6s8f  xwM2aC7IdeMC0   \n",
       "1      6hQ9lNX  LM8l689qOp     NaN    ELof    xb3V     RAYp        55YFVY9   \n",
       "2      catzS2D  LM8l689qOp     NaN     NaN    FSa2     ZI9m  ib5G6X1eUxUn6   \n",
       "3      e4lqvY0  LM8l689qOp     NaN     NaN    xb3V     RAYp  F2FyR07IdsN7I   \n",
       "4      MAz3HNj  LM8l689qOp     NaN     NaN    WqMG     RAYp  F2FyR07IdsN7I   \n",
       "...        ...         ...     ...     ...     ...      ...            ...   \n",
       "18294  mErwEWL  LM8l689qOp     NaN     NaN    uWr3     RAYp  F2FyR07IdsN7I   \n",
       "18295  catzS2D  LM8l689qOp     NaN    kG3k    uWr3     ZI9m  ib5G6X1eUxUn6   \n",
       "18296  catzS2D  LM8l689qOp     NaN    ELof    Qcbd     ZI9m        55YFVY9   \n",
       "18297  wg_DmEs  LM8l689qOp     NaN     NaN    WqMG     RAYp  F2FyR07IdsN7I   \n",
       "18298      NaN         NaN     NaN     NaN     NaN      NaN            NaN   \n",
       "\n",
       "       Var229  Var230  labels  \n",
       "0         NaN     NaN    -1.0  \n",
       "1        mj86     NaN    -1.0  \n",
       "2        mj86     NaN    -1.0  \n",
       "3         NaN     NaN     1.0  \n",
       "4         NaN     NaN    -1.0  \n",
       "...       ...     ...     ...  \n",
       "18294     NaN     NaN    -1.0  \n",
       "18295    am7c     NaN     1.0  \n",
       "18296    am7c     NaN    -1.0  \n",
       "18297     NaN     NaN    -1.0  \n",
       "18298     NaN     NaN     NaN  \n",
       "\n",
       "[18299 rows x 232 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download Train Data\n",
    "train_data = pd.read_csv('orange_small_churn_train_data.csv')\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "SEED = 23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are missing values for the target feate. Let's find out how many "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['labels'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only one missing value, drop it \n",
    "train_data.drop(index=18298, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the target\n",
    "train_data.rename(columns={'labels':'is_churn'}, inplace=True)\n",
    "\n",
    "# Drop ID column\n",
    "train_data.drop('ID', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the features (numeric/categorical)\n",
    "num_features = train_data.iloc[:, :190]\n",
    "cat_features = train_data.iloc[:, 190:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are features that consits of only missing values. Find them and drop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 16 Columns\n",
      "Dropped 2 Columns\n"
     ]
    }
   ],
   "source": [
    "# Create a suitable function for dropping columns that have only NaN values\n",
    "def drop_nan_columns(df):    \n",
    "    feat_to_drop = [feature for feature in df.columns if df[feature].isna().all()]\n",
    "\n",
    "    print(f'Dropped {len(feat_to_drop)} Columns')\n",
    "    df.drop(columns=feat_to_drop, axis=1, inplace=True)\n",
    "    \n",
    "# Drop these columns \n",
    "drop_nan_columns(num_features)\n",
    "drop_nan_columns(cat_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial preprocessing is done. For now, we can proceed and deal with *categorical/numeric* features\n",
    "\n",
    "### Baseline \n",
    "We are going to **process *categorical/numeric* features separately.** We have a lot of numeric features and not so many categorical. For this purpose, we have the following plan. Firstly, build a model with only numeric features and estimate the quality, then with only categorical and again test the model. Finally, combine them and get the final score.\n",
    "\n",
    "### Numerci Features\n",
    "We've already conducted the initial data analysis. For these features, we've measured the correlation (mathematical expectation difference for different classes). **The main problem was many missing values.** Apply imputation for a feature with a 90% missing value just doesn't make any sense. Dependencies are complicated especially taking into account class imbalance. The following solution is proposed:\n",
    "- Look at NaN ratio for features and select features that don't exceed a certain threshold. Then apply imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define a fucntion for plotting NaN ration \n",
    "def plot_nan_ration(df, figsize=(10,5), title='Numerical Features'):\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    plt.hist(df.iloc[:,:-1].isna().sum()/df.shape[0])\n",
    "    plt.xlabel('NaN Fraction')\n",
    "    plt.ylabel('Number of Features')\n",
    "    plt.title(title)\n",
    "    plt.grid();\n",
    "    \n",
    "plot_nan_ration(num_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe from the graph above that there are 3 areas:\n",
    "- NaN ratio `90~100%` (~ 140 features)\n",
    "- NaN ratio `40~60%` (not many)\n",
    "- NaN ratio `0~30%` (~35 features)\n",
    "\n",
    "Since we are building a baseline solution we are not going to complicate it. \n",
    "\n",
    "Just **define 30% threshold** (i.e. features with more than 30% missing values are excluded from the research)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features with NaN ratio less than 30%\n",
    "temp_frame = num_features.isna().sum()/num_features.shape[0]\n",
    "columns = temp_frame[temp_frame < 0.3].index\n",
    "\n",
    "num_features = num_features[columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we have to fill in missing values. The main options are:\n",
    "- Fill with median/mean\n",
    "- Use a model (e.g. KNN)\n",
    "- Apply MICE algorithm\n",
    "\n",
    "We will choose KNN as it seems more reliable\n",
    "\n",
    "To prevent data leakage, we have to use `Pipeline` for more precise model estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a suitable function for model cross-validation\n",
    "def show_models_cv_pipeline(models, cv_type, x_train, y_train, metrics, is_aggregated=True):\n",
    "    res_df = pd.DataFrame()\n",
    "    \n",
    "    for model in log_progress(models):\n",
    "        model_pipeline = Pipeline([\n",
    "            ('data_imputing', KNNImputer()),\n",
    "            ('data_scaling', StandardScaler()),\n",
    "            ('model', model)\n",
    "        ])\n",
    "    \n",
    "        cv_results = cross_validate(model_pipeline, X=x_train, y=y_train, cv=cv_type, scoring=metrics)\n",
    "        cv_results['Model'] = str(model).split('(')[0] # extract the current model name \n",
    "        res_df = res_df.append(pd.DataFrame(cv_results))\n",
    "        \n",
    "    # Make the first column model_name and  get rid of irrelevant columns\n",
    "    new_columns_order = list(res_df.columns[2:-1])\n",
    "    new_columns_order.insert(0, 'Model')\n",
    "    \n",
    "    # Returns aggregated/fold estimation \n",
    "    if is_aggregated:\n",
    "        return res_df[new_columns_order].groupby(by='Model').mean()\n",
    "    else:\n",
    "        return res_df[new_columns_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix of features and labels\n",
    "x_train = num_features\n",
    "y_train = train_data['is_churn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline models:\n",
    "- Random Forest\n",
    "- Gradient Boosting\n",
    "- Logistic Regression\n",
    "- Ridge Classifier\n",
    "- SVM Classifier\n",
    "\n",
    "Since the dataset is imbalances, for each model we apply the following parameter:\n",
    "- `class_weight='balanced'` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3c5d24352f0407eb45d414a0401d1d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wall time: 16min 53s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_roc_auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GradientBoostingClassifier</th>\n",
       "      <td>0.210714</td>\n",
       "      <td>0.003634</td>\n",
       "      <td>0.007108</td>\n",
       "      <td>0.689451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.099658</td>\n",
       "      <td>0.631816</td>\n",
       "      <td>0.172155</td>\n",
       "      <td>0.614839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000727</td>\n",
       "      <td>0.001449</td>\n",
       "      <td>0.645503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeClassifier</th>\n",
       "      <td>0.099683</td>\n",
       "      <td>0.628891</td>\n",
       "      <td>0.172083</td>\n",
       "      <td>0.614684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.109261</td>\n",
       "      <td>0.578097</td>\n",
       "      <td>0.183784</td>\n",
       "      <td>0.626358</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            test_precision  test_recall   test_f1  \\\n",
       "Model                                                               \n",
       "GradientBoostingClassifier        0.210714     0.003634  0.007108   \n",
       "LogisticRegression                0.099658     0.631816  0.172155   \n",
       "RandomForestClassifier            0.200000     0.000727  0.001449   \n",
       "RidgeClassifier                   0.099683     0.628891  0.172083   \n",
       "SVC                               0.109261     0.578097  0.183784   \n",
       "\n",
       "                            test_roc_auc  \n",
       "Model                                     \n",
       "GradientBoostingClassifier      0.689451  \n",
       "LogisticRegression              0.614839  \n",
       "RandomForestClassifier          0.645503  \n",
       "RidgeClassifier                 0.614684  \n",
       "SVC                             0.626358  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Main Models\n",
    "models = [\n",
    "    RandomForestClassifier(class_weight='balanced', n_jobs=-1, random_state=SEED),\n",
    "    GradientBoostingClassifier(random_state=SEED),\n",
    "    LogisticRegression(class_weight='balanced', n_jobs=-1, random_state=SEED, solver='liblinear', penalty='l1'),\n",
    "    RidgeClassifier(class_weight='balanced', random_state=SEED),\n",
    "    svm.SVC(class_weight='balanced', random_state=SEED)\n",
    "]\n",
    "  \n",
    "# Cross-validation\n",
    "cros_val_res = show_models_cv_pipeline(models=models,\n",
    "                                       x_train=x_train,\n",
    "                                       y_train=y_train,\n",
    "                                       cv_type=StratifiedKFold(shuffle=True, random_state=SEED),\n",
    "                                       metrics=['precision', 'recall', 'f1', 'roc_auc'],\n",
    "                                       is_aggregated=True)\n",
    "cros_val_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually, it would be better to apply another method for imputing missing values because with KNN it takes much time.\n",
    "\n",
    "It's important to have class balance. `GradientBoostingClassifier` doesn't have a parameter for class balancing and its estimation is a bit weird (good `ROC-AUC` but the rest metrics are bad)\n",
    "\n",
    "The results are not bad. Let's look what quality we will get using categorical features.\n",
    "\n",
    "### Categorical Features\n",
    "Categorical features have many missing values as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# NaN ration for categorical features\n",
    "plot_nan_ration(cat_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see several groups with different NaN ratio. let's apply a  20% threshold and select the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features that have less than 20% missing values\n",
    "temp_frame = cat_features.isna().sum()/cat_features.shape[0]\n",
    "columns = temp_frame[temp_frame < 0.2].index\n",
    "\n",
    "cat_features = cat_features[columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After selecting the features we can apply imputation. There are several options:\n",
    "- Define a missing value as a new category `unknown`\n",
    "- Fill missing values the most frequent category (mode)\n",
    "\n",
    "As before we are using `Pipeline` with cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for getting binary/categorical feature names\n",
    "def return_bin_cat_columns(df):\n",
    "    bin_columns = [feature for feature in df.columns if df[feature].value_counts().shape[0] == 2]\n",
    "    cat_columns = df.columns.difference(bin_columns).to_list()\n",
    "    \n",
    "    return bin_columns, cat_columns\n",
    "\n",
    "bin_columns, cat_columns = return_bin_cat_columns(cat_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to process binary and categorical features separately. Add these stages in the `Pipeline`. For this purpose, use `ColumnTransformer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline Definition\n",
    "\n",
    "# Binary features processing\n",
    "binary_pipeline = Pipeline([\n",
    "    ('binary_imputing', SimpleImputer(strategy='most_frequent')),\n",
    "    ('binary_encoding', OrdinalEncoder())\n",
    "])\n",
    "\n",
    "# Categorical features processing\n",
    "cat_pipeline = Pipeline([\n",
    "    ('cat_imputing', SimpleImputer(strategy='most_frequent')),\n",
    "    ('cat_encoding', OneHotEncoder(sparse=True, handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combine transformations\n",
    "transformations = [\n",
    "    ('bin_transformations', binary_pipeline, bin_columns),\n",
    "    ('cat_transformations', cat_pipeline, cat_columns)\n",
    "]\n",
    "\n",
    "cat_bin_transformations = ColumnTransformer(transformers=transformations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51c343f1d16144b6979d25dc8713257f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wall time: 4min 1s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_roc_auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GradientBoostingClassifier</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.001452</td>\n",
       "      <td>0.002893</td>\n",
       "      <td>0.641844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.156809</td>\n",
       "      <td>0.255618</td>\n",
       "      <td>0.194326</td>\n",
       "      <td>0.627324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.001452</td>\n",
       "      <td>0.002893</td>\n",
       "      <td>0.601913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeClassifier</th>\n",
       "      <td>0.058902</td>\n",
       "      <td>0.432835</td>\n",
       "      <td>0.103692</td>\n",
       "      <td>0.412177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.177266</td>\n",
       "      <td>0.187349</td>\n",
       "      <td>0.182117</td>\n",
       "      <td>0.629111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            test_precision  test_recall   test_f1  \\\n",
       "Model                                                               \n",
       "GradientBoostingClassifier        0.400000     0.001452  0.002893   \n",
       "LogisticRegression                0.156809     0.255618  0.194326   \n",
       "RandomForestClassifier            0.400000     0.001452  0.002893   \n",
       "RidgeClassifier                   0.058902     0.432835  0.103692   \n",
       "SVC                               0.177266     0.187349  0.182117   \n",
       "\n",
       "                            test_roc_auc  \n",
       "Model                                     \n",
       "GradientBoostingClassifier      0.641844  \n",
       "LogisticRegression              0.627324  \n",
       "RandomForestClassifier          0.601913  \n",
       "RidgeClassifier                 0.412177  \n",
       "SVC                             0.629111  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Modify the following function\n",
    "def show_model_cvs_pipeline_cat_bin(models, cv_type, x_train, y_train, metrics, is_aggregated=True):\n",
    "    res_df = pd.DataFrame()\n",
    "    \n",
    "    for model in log_progress(models):\n",
    "        model_pipeline = Pipeline([\n",
    "            ('cat_bin_transformations', cat_bin_transformations),\n",
    "            ('model', model)\n",
    "        ])\n",
    "        \n",
    "        cv_results = cross_validate(model_pipeline, X=x_train, y=y_train, cv=cv_type, scoring=metrics, error_score='raise')\n",
    "        cv_results['Model'] = str(model).split('(')[0] \n",
    "        res_df = res_df.append(pd.DataFrame(cv_results))\n",
    "        \n",
    "    new_columns_order = list(res_df.columns[2:-1])\n",
    "    new_columns_order.insert(0, 'Model')\n",
    "\n",
    "    if is_aggregated:\n",
    "        return res_df[new_columns_order].groupby(by='Model').mean()\n",
    "    else:\n",
    "        return res_df[new_columns_order]\n",
    "\n",
    "# Cross-validate\n",
    "cros_val_res = show_model_cvs_pipeline_cat_bin(models=models,\n",
    "                                               x_train=cat_features,\n",
    "                                               y_train=y_train,\n",
    "                                               cv_type=StratifiedKFold(shuffle=True, random_state=SEED),\n",
    "                                               metrics=['precision', 'recall', 'f1', 'roc_auc'],\n",
    "                                               is_aggregated=True)\n",
    "cros_val_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quality on only categorical features is less in comparison with numeric features. Now, let's combine all features and estimate the quality of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add in the Pipeline Numeric features processing\n",
    "num_columns = num_features.columns.to_list()\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    ('data_imputing', KNNImputer()),\n",
    "    ('data_scaling', StandardScaler())\n",
    "])\n",
    "\n",
    "# Combine the transformations\n",
    "transformations = [\n",
    "    ('num_transformations', num_pipeline, num_columns),\n",
    "    ('bin_transformations', binary_pipeline, bin_columns),\n",
    "    ('cat_transformations', cat_pipeline, cat_columns)\n",
    "]\n",
    "\n",
    "feature_transformations = ColumnTransformer(transformers=transformations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New matrix of features\n",
    "x_train = pd.concat([num_features, cat_features], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7af9dfd7bb34a49856abe09d5ab4634",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wall time: 7min 13s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_roc_auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GradientBoostingClassifier</th>\n",
       "      <td>0.322143</td>\n",
       "      <td>0.006543</td>\n",
       "      <td>0.012772</td>\n",
       "      <td>0.704115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.158200</td>\n",
       "      <td>0.261423</td>\n",
       "      <td>0.197074</td>\n",
       "      <td>0.634839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.640363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeClassifier</th>\n",
       "      <td>0.057995</td>\n",
       "      <td>0.426314</td>\n",
       "      <td>0.102100</td>\n",
       "      <td>0.408890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.157182</td>\n",
       "      <td>0.287576</td>\n",
       "      <td>0.203215</td>\n",
       "      <td>0.654916</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            test_precision  test_recall   test_f1  \\\n",
       "Model                                                               \n",
       "GradientBoostingClassifier        0.322143     0.006543  0.012772   \n",
       "LogisticRegression                0.158200     0.261423  0.197074   \n",
       "RandomForestClassifier            0.000000     0.000000  0.000000   \n",
       "RidgeClassifier                   0.057995     0.426314  0.102100   \n",
       "SVC                               0.157182     0.287576  0.203215   \n",
       "\n",
       "                            test_roc_auc  \n",
       "Model                                     \n",
       "GradientBoostingClassifier      0.704115  \n",
       "LogisticRegression              0.634839  \n",
       "RandomForestClassifier          0.640363  \n",
       "RidgeClassifier                 0.408890  \n",
       "SVC                             0.654916  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Again modify the function \n",
    "def show_model_cvs_pipeline_all_features(models, cv_type, x_train, y_train, metrics, is_aggregated=True):\n",
    "    res_df = pd.DataFrame()\n",
    "    \n",
    "    for model in log_progress(models):\n",
    "        model_pipeline = Pipeline([\n",
    "            ('feature_transformations', feature_transformations),\n",
    "            ('model', model)\n",
    "        ])\n",
    "        \n",
    "        cv_results = cross_validate(model_pipeline, X=x_train, y=y_train, cv=cv_type,\n",
    "                                    scoring=metrics, error_score='raise', n_jobs=-1)\n",
    "        \n",
    "        cv_results['Model'] = str(model).split('(')[0] \n",
    "        res_df = res_df.append(pd.DataFrame(cv_results))\n",
    "        \n",
    "    new_columns_order = list(res_df.columns[2:-1])\n",
    "    new_columns_order.insert(0, 'Model')\n",
    "    \n",
    "    if is_aggregated:\n",
    "        return res_df[new_columns_order].groupby(by='Model').mean()\n",
    "    else:\n",
    "        return res_df[new_columns_order]\n",
    "\n",
    "cros_val_res = show_model_cvs_pipeline_all_features(models=models,\n",
    "                                                    x_train=x_train,\n",
    "                                                    y_train=y_train,\n",
    "                                                    cv_type=StratifiedKFold(shuffle=True, random_state=SEED),\n",
    "                                                    metrics=['precision', 'recall', 'f1', 'roc_auc'],\n",
    "                                                    is_aggregated=True)\n",
    "cros_val_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On all features quality is good. To get more details about the qulaity, look at each fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d62f7939cecd43aaa1a44c920844d10f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.648014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.633017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.646612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.639130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.635042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.035336</td>\n",
       "      <td>0.722954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.699551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.003623</td>\n",
       "      <td>0.007117</td>\n",
       "      <td>0.689047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.003636</td>\n",
       "      <td>0.007220</td>\n",
       "      <td>0.717122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.007273</td>\n",
       "      <td>0.014184</td>\n",
       "      <td>0.691904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.163755</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.204638</td>\n",
       "      <td>0.633481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.159574</td>\n",
       "      <td>0.271739</td>\n",
       "      <td>0.201072</td>\n",
       "      <td>0.641773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.164114</td>\n",
       "      <td>0.271739</td>\n",
       "      <td>0.204638</td>\n",
       "      <td>0.640368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.163043</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.204082</td>\n",
       "      <td>0.637445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.140515</td>\n",
       "      <td>0.218182</td>\n",
       "      <td>0.170940</td>\n",
       "      <td>0.621130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RidgeClassifier</td>\n",
       "      <td>0.057443</td>\n",
       "      <td>0.418182</td>\n",
       "      <td>0.101010</td>\n",
       "      <td>0.404867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RidgeClassifier</td>\n",
       "      <td>0.056028</td>\n",
       "      <td>0.405797</td>\n",
       "      <td>0.098462</td>\n",
       "      <td>0.421379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RidgeClassifier</td>\n",
       "      <td>0.055746</td>\n",
       "      <td>0.413043</td>\n",
       "      <td>0.098234</td>\n",
       "      <td>0.391688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RidgeClassifier</td>\n",
       "      <td>0.057494</td>\n",
       "      <td>0.425455</td>\n",
       "      <td>0.101299</td>\n",
       "      <td>0.398243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RidgeClassifier</td>\n",
       "      <td>0.063266</td>\n",
       "      <td>0.469091</td>\n",
       "      <td>0.111495</td>\n",
       "      <td>0.428274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.345455</td>\n",
       "      <td>0.241117</td>\n",
       "      <td>0.674892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.162476</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.211854</td>\n",
       "      <td>0.648685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.148936</td>\n",
       "      <td>0.278986</td>\n",
       "      <td>0.194199</td>\n",
       "      <td>0.657169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.145877</td>\n",
       "      <td>0.250909</td>\n",
       "      <td>0.184492</td>\n",
       "      <td>0.646083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.143434</td>\n",
       "      <td>0.258182</td>\n",
       "      <td>0.184416</td>\n",
       "      <td>0.647754</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model  test_precision  test_recall   test_f1  \\\n",
       "0      RandomForestClassifier        0.000000     0.000000  0.000000   \n",
       "1      RandomForestClassifier        0.000000     0.000000  0.000000   \n",
       "2      RandomForestClassifier        0.000000     0.000000  0.000000   \n",
       "3      RandomForestClassifier        0.000000     0.000000  0.000000   \n",
       "4      RandomForestClassifier        0.000000     0.000000  0.000000   \n",
       "0  GradientBoostingClassifier        0.625000     0.018182  0.035336   \n",
       "1  GradientBoostingClassifier        0.000000     0.000000  0.000000   \n",
       "2  GradientBoostingClassifier        0.200000     0.003623  0.007117   \n",
       "3  GradientBoostingClassifier        0.500000     0.003636  0.007220   \n",
       "4  GradientBoostingClassifier        0.285714     0.007273  0.014184   \n",
       "0          LogisticRegression        0.163755     0.272727  0.204638   \n",
       "1          LogisticRegression        0.159574     0.271739  0.201072   \n",
       "2          LogisticRegression        0.164114     0.271739  0.204638   \n",
       "3          LogisticRegression        0.163043     0.272727  0.204082   \n",
       "4          LogisticRegression        0.140515     0.218182  0.170940   \n",
       "0             RidgeClassifier        0.057443     0.418182  0.101010   \n",
       "1             RidgeClassifier        0.056028     0.405797  0.098462   \n",
       "2             RidgeClassifier        0.055746     0.413043  0.098234   \n",
       "3             RidgeClassifier        0.057494     0.425455  0.101299   \n",
       "4             RidgeClassifier        0.063266     0.469091  0.111495   \n",
       "0                         SVC        0.185185     0.345455  0.241117   \n",
       "1                         SVC        0.162476     0.304348  0.211854   \n",
       "2                         SVC        0.148936     0.278986  0.194199   \n",
       "3                         SVC        0.145877     0.250909  0.184492   \n",
       "4                         SVC        0.143434     0.258182  0.184416   \n",
       "\n",
       "   test_roc_auc  \n",
       "0      0.648014  \n",
       "1      0.633017  \n",
       "2      0.646612  \n",
       "3      0.639130  \n",
       "4      0.635042  \n",
       "0      0.722954  \n",
       "1      0.699551  \n",
       "2      0.689047  \n",
       "3      0.717122  \n",
       "4      0.691904  \n",
       "0      0.633481  \n",
       "1      0.641773  \n",
       "2      0.640368  \n",
       "3      0.637445  \n",
       "4      0.621130  \n",
       "0      0.404867  \n",
       "1      0.421379  \n",
       "2      0.391688  \n",
       "3      0.398243  \n",
       "4      0.428274  \n",
       "0      0.674892  \n",
       "1      0.648685  \n",
       "2      0.657169  \n",
       "3      0.646083  \n",
       "4      0.647754  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cros_val_res = show_model_cvs_pipeline_all_features(models=models,\n",
    "                                                    x_train=x_train,\n",
    "                                                    y_train=y_train,\n",
    "                                                    cv_type=StratifiedKFold(shuffle=True, random_state=SEED),\n",
    "                                                    metrics=['precision', 'recall', 'f1', 'roc_auc'],\n",
    "                                                    is_aggregated=False)\n",
    "cros_val_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "The obtained quality is not bad and this is the baseline quality. Next, we are going to apply more precise feature selection and experiments with the features to improve the quality. We've also looked at the quality on each fold and can conclude that not all models are good at finding the `churn` class. `RandomForestClassifier` even with parameter `class_weight='balanced'` is bad at finding the `churn`.\n",
    "\n",
    "**Random Forest**\n",
    "\n",
    "Most of the time finds the majority class `not_churn`. On all 5 folds, it was finding only `not_churn`.\n",
    "\n",
    "**Gradient Boosting**\n",
    "\n",
    "A bit better, `precision` and `recall` are different from zero.\n",
    "\n",
    "**Logistic Regression**\n",
    "\n",
    "Not bad results in terms of `precision` and `recall`. However, `roc_auc` is lower in comparison with `Gradient Boosting`\n",
    "\n",
    "**Ridge Classifier**\n",
    "Poor metrics results, the worst model\n",
    "\n",
    "Since the main metric of the competition is `ROC-AUC` we will consider this metric. We can conclude that the best model is `GradientBoostingClassifier`. Besides, tree models outperform linear ones.\n",
    "\n",
    "### Baseline Quality on Test Data\n",
    "Let's test *baseline* on kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some functions\n",
    "def to_submission(data, f_name):\n",
    "    result = pd.DataFrame({'Id':range(data.shape[0]),\n",
    "                           'result':data[:,1]})\n",
    "    result.to_csv(f_name, index=False)\n",
    "\n",
    "def make_submission_using_pipeline(models, x_train, y_train, x_test, f_names):\n",
    "    \n",
    "    predictions = []\n",
    "    \n",
    "    for model in log_progress(models):\n",
    "        model_pipeline = Pipeline([\n",
    "            ('feature_transformations', feature_transformations),\n",
    "            ('model', model)\n",
    "        ])\n",
    "        model_pipeline.fit(x_train, y_train)\n",
    "        predictions.append(model_pipeline.predict_proba(x_test))\n",
    "        \n",
    "    \n",
    "    for indx, pred in enumerate(predictions):\n",
    "        to_submission(pred, f_name=f_names[indx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results showed that the best models are:\n",
    "- GradientBoostingClassifier\n",
    "- SVC\n",
    "\n",
    "Test them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var6</th>\n",
       "      <th>Var7</th>\n",
       "      <th>Var13</th>\n",
       "      <th>Var21</th>\n",
       "      <th>Var22</th>\n",
       "      <th>Var24</th>\n",
       "      <th>Var25</th>\n",
       "      <th>Var28</th>\n",
       "      <th>Var35</th>\n",
       "      <th>Var38</th>\n",
       "      <th>...</th>\n",
       "      <th>Var217</th>\n",
       "      <th>Var218</th>\n",
       "      <th>Var219</th>\n",
       "      <th>Var220</th>\n",
       "      <th>Var221</th>\n",
       "      <th>Var222</th>\n",
       "      <th>Var223</th>\n",
       "      <th>Var226</th>\n",
       "      <th>Var227</th>\n",
       "      <th>Var228</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1225.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2352.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>388.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6726960.0</td>\n",
       "      <td>...</td>\n",
       "      <td>jgOV</td>\n",
       "      <td>UYBR</td>\n",
       "      <td>FzaX</td>\n",
       "      <td>UF16siJ</td>\n",
       "      <td>zCkv</td>\n",
       "      <td>APgdzOv</td>\n",
       "      <td>jySVZNlOJy</td>\n",
       "      <td>xb3V</td>\n",
       "      <td>6fzt</td>\n",
       "      <td>Zy3gnGM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>896.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1560.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>133.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>PDRj</td>\n",
       "      <td>cJvF</td>\n",
       "      <td>FzaX</td>\n",
       "      <td>ot6oLzk</td>\n",
       "      <td>oslk</td>\n",
       "      <td>IIvC99a</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>xb3V</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>791.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2824.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>324.48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2988486.0</td>\n",
       "      <td>...</td>\n",
       "      <td>laMb</td>\n",
       "      <td>UYBR</td>\n",
       "      <td>FzaX</td>\n",
       "      <td>6VLNqhB</td>\n",
       "      <td>oslk</td>\n",
       "      <td>6YSocsg</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>rgKb</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2296.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3732.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>286.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6637740.0</td>\n",
       "      <td>...</td>\n",
       "      <td>qLRt</td>\n",
       "      <td>UYBR</td>\n",
       "      <td>FzaX</td>\n",
       "      <td>tzp8jNM</td>\n",
       "      <td>oslk</td>\n",
       "      <td>5nQ7A2G</td>\n",
       "      <td>jySVZNlOJy</td>\n",
       "      <td>rgKb</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>XqfQ</td>\n",
       "      <td>UYBR</td>\n",
       "      <td>FzaX</td>\n",
       "      <td>EPImS85</td>\n",
       "      <td>oslk</td>\n",
       "      <td>MI8s5nE</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>7P5s</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>714.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2240.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>133.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>vawI</td>\n",
       "      <td>cJvF</td>\n",
       "      <td>Lmli</td>\n",
       "      <td>ch2oGfM</td>\n",
       "      <td>zCkv</td>\n",
       "      <td>P6pu4Vl</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>xb3V</td>\n",
       "      <td>ZI9m</td>\n",
       "      <td>R4y5gQQWY8OodqDV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>812.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>253.52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4147200.0</td>\n",
       "      <td>...</td>\n",
       "      <td>jQNd</td>\n",
       "      <td>cJvF</td>\n",
       "      <td>FzaX</td>\n",
       "      <td>8d5YWu3</td>\n",
       "      <td>oslk</td>\n",
       "      <td>sXbT3Cb</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>WqMG</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>55YFVY9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>819.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>321.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1555200.0</td>\n",
       "      <td>...</td>\n",
       "      <td>g9B7</td>\n",
       "      <td>cJvF</td>\n",
       "      <td>FzaX</td>\n",
       "      <td>WdPoLzk</td>\n",
       "      <td>oslk</td>\n",
       "      <td>05jAV0N</td>\n",
       "      <td>M_8D</td>\n",
       "      <td>TNEC</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>55YFVY9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>BCds</td>\n",
       "      <td>UYBR</td>\n",
       "      <td>FzaX</td>\n",
       "      <td>EMvv4zN</td>\n",
       "      <td>oslk</td>\n",
       "      <td>RDY7kpB</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>uWr3</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>55YFVY9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>868.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2820.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>461.92</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6471180.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7mgE</td>\n",
       "      <td>cJvF</td>\n",
       "      <td>FzaX</td>\n",
       "      <td>bDIDFjT</td>\n",
       "      <td>oslk</td>\n",
       "      <td>gsLzpoz</td>\n",
       "      <td>jySVZNlOJy</td>\n",
       "      <td>me1d</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Var6  Var7   Var13  Var21  Var22  Var24  Var25   Var28  Var35  \\\n",
       "0     1225.0   7.0  2352.0  180.0  225.0    0.0   56.0  388.08    0.0   \n",
       "1      896.0  14.0  1560.0  112.0  140.0    0.0   96.0  133.12    0.0   \n",
       "2      791.0   7.0  2824.0  172.0  215.0    4.0   16.0  324.48    0.0   \n",
       "3     2296.0   7.0  3732.0  480.0  600.0   10.0  104.0  286.96    0.0   \n",
       "4        NaN   NaN     NaN    NaN    NaN    NaN    NaN     NaN    NaN   \n",
       "...      ...   ...     ...    ...    ...    ...    ...     ...    ...   \n",
       "9995   714.0   7.0  2240.0  120.0  150.0   10.0   80.0  133.12    0.0   \n",
       "9996   812.0   7.0  2020.0  136.0  170.0    0.0  104.0  253.52    0.0   \n",
       "9997   819.0   7.0    40.0  120.0  150.0    0.0   56.0  321.28    0.0   \n",
       "9998     NaN   7.0   112.0    NaN    0.0    NaN    0.0    0.00    0.0   \n",
       "9999   868.0  14.0  2820.0  136.0  170.0    2.0    8.0  461.92    0.0   \n",
       "\n",
       "          Var38  ...  Var217  Var218  Var219   Var220  Var221   Var222  \\\n",
       "0     6726960.0  ...    jgOV    UYBR    FzaX  UF16siJ    zCkv  APgdzOv   \n",
       "1           0.0  ...    PDRj    cJvF    FzaX  ot6oLzk    oslk  IIvC99a   \n",
       "2     2988486.0  ...    laMb    UYBR    FzaX  6VLNqhB    oslk  6YSocsg   \n",
       "3     6637740.0  ...    qLRt    UYBR    FzaX  tzp8jNM    oslk  5nQ7A2G   \n",
       "4           NaN  ...    XqfQ    UYBR    FzaX  EPImS85    oslk  MI8s5nE   \n",
       "...         ...  ...     ...     ...     ...      ...     ...      ...   \n",
       "9995        0.0  ...    vawI    cJvF    Lmli  ch2oGfM    zCkv  P6pu4Vl   \n",
       "9996  4147200.0  ...    jQNd    cJvF    FzaX  8d5YWu3    oslk  sXbT3Cb   \n",
       "9997  1555200.0  ...    g9B7    cJvF    FzaX  WdPoLzk    oslk  05jAV0N   \n",
       "9998        0.0  ...    BCds    UYBR    FzaX  EMvv4zN    oslk  RDY7kpB   \n",
       "9999  6471180.0  ...    7mgE    cJvF    FzaX  bDIDFjT    oslk  gsLzpoz   \n",
       "\n",
       "          Var223  Var226  Var227            Var228  \n",
       "0     jySVZNlOJy    xb3V    6fzt           Zy3gnGM  \n",
       "1     LM8l689qOp    xb3V    RAYp     F2FyR07IdsN7I  \n",
       "2     LM8l689qOp    rgKb    RAYp     F2FyR07IdsN7I  \n",
       "3     jySVZNlOJy    rgKb    RAYp     F2FyR07IdsN7I  \n",
       "4     LM8l689qOp    7P5s    RAYp     F2FyR07IdsN7I  \n",
       "...          ...     ...     ...               ...  \n",
       "9995  LM8l689qOp    xb3V    ZI9m  R4y5gQQWY8OodqDV  \n",
       "9996  LM8l689qOp    WqMG    RAYp           55YFVY9  \n",
       "9997        M_8D    TNEC    RAYp           55YFVY9  \n",
       "9998  LM8l689qOp    uWr3    RAYp           55YFVY9  \n",
       "9999  jySVZNlOJy    me1d    RAYp     F2FyR07IdsN7I  \n",
       "\n",
       "[10000 rows x 67 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test data loading \n",
    "test_data = pd.read_csv('orange_small_churn_test_data.csv')\n",
    "x_test = test_data[x_train.columns]\n",
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e030f0d3fb81446c88ca1e594bee2dc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "    GradientBoostingClassifier(random_state=SEED),\n",
    "    svm.SVC(class_weight='balanced', random_state=SEED, probability=True)\n",
    "]\n",
    "\n",
    "make_submission_using_pipeline(models=models,\n",
    "                               x_train=x_train,\n",
    "                               y_train=y_train,\n",
    "                               x_test=x_test,\n",
    "                               f_names=['gb_pipeline_baseline.csv', 'svc_pipeline_baseline.csv'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results \n",
    "- GradientBoostingClassifier (`0.68784`)\n",
    "- SVC (`0.64952`)\n",
    "\n",
    "Next we are going use as a main model `GradientBoostingClassifier`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
