{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from nltk.corpus import movie_reviews\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "negids = movie_reviews.fileids('neg')\n",
    "posids = movie_reviews.fileids('pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_rev = [movie_reviews.words(fileids=[f]) for f in negids]\n",
    "pos_rev = [movie_reviews.words(fileids=[f]) for f in posids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative Review Shape:  1000\n",
      "Positive Review Shape:  1000\n"
     ]
    }
   ],
   "source": [
    "print('Negative Review Shape: ', len(neg_rev))\n",
    "print('Positive Review Shape: ', len(pos_rev))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Каждый объект имеет тип:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nltk.corpus.reader.util.StreamBackedCorpusView"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pos_rev[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее, чтобы использовать `CountVectorizer()` представим каждый текст строкой. \n",
    "\n",
    "Таким образом мы получим список строк, где каждая строка это текст."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_rev = [' '.join(movie_reviews.words(fileids=f)) for f in negids]\n",
    "pos_rev = [' '.join(movie_reviews.words(fileids=f)) for f in posids]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создайте список из текстов всех имеющихся отзывов, а также список с классами, которые будет использовать ваш классификатор - 0 для негативных отзывов и 1 для позитивных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_reviews = neg_rev + pos_rev\n",
    "labels = np.array([0 for _ in range(1000)] + [1 for _ in range(1000)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подсчитайте количество отзывов в выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N Reviews:  2000\n"
     ]
    }
   ],
   "source": [
    "print('N Reviews: ', len(all_reviews))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подсчитайте долю класса 1 в выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Review Shape:  1000\n"
     ]
    }
   ],
   "source": [
    "print('Positive Review Shape: ', len(pos_rev))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируйте `CountVectorizer` из `sklearn.feature_extraction.text` Попробуйте использовать его с настройками по умолчанию для того, чтобы получить признаковое представление каждого текста. Скорее всего, попытка не увенчается успехом. Разберитесь, в чем причина, и добейтесь того, чтобы метод `fit_transform` у `CountVectorizer` успешно отрабатывал. Подсчитайте количество признаков в `CountVectorizer`.\n",
    "\n",
    "Никакой предварительной обработки текста (удаление стоп-слов, нормализация слов) на этом шаге делать не надо, в качестве признаков должны использоваться частоты слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N Features:  39659\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(all_reviews)\n",
    "\n",
    "print('N Features: ', len(vectorizer.get_feature_names()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Соберите `pipeline` из `CountVectorizer` и `LogisticRegression` c настройками по-умолчанию и с помощью `cross_val_score` (также со стандартными настройками) оцените получаемое \"из коробки\" качество по `accuracy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy CV:  0.841\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('feat_gen', CountVectorizer()),\n",
    "    ('model', LogisticRegression(solver='liblinear'))\n",
    "])\n",
    "\n",
    "cv_results = cross_val_score(pipeline, X=all_reviews, y=labels, n_jobs=-1, scoring='accuracy', error_score='raise')\n",
    "print('Accuracy CV: ', np.mean(cv_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аналогично accuracy, оцените качество по `ROC-AUC`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC CV:  0.916\n"
     ]
    }
   ],
   "source": [
    "cv_results = cross_val_score(pipeline, X=all_reviews, y=labels, n_jobs=-1, scoring='roc_auc', error_score='raise')\n",
    "print('ROC-AUC CV: ', round(np.mean(cv_results),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите логистическую регрессию на всей доступной вам выборке и выведите 5 наиболее важных для модели признаков (подумайте, какие именно признаки стоит считать такими). \n",
    "\n",
    "Вам могут пригодиться метод `get_feature_names()` или поле `vocabulary_` у класса `CountVectorizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(solver='liblinear')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(all_reviews)\n",
    "\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "model.fit(X, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Features:\n",
      "                 0\n",
      "techie    0.782254\n",
      "khe       0.636624\n",
      "moff      0.592839\n",
      "unsigned  0.556051\n",
      "ankles    0.508191\n"
     ]
    }
   ],
   "source": [
    "imp_dict = dict(zip(vectorizer.vocabulary_.keys(), model.coef_[0]))\n",
    "\n",
    "feat_imp = pd.DataFrame(imp_dict, index=[0]).T\n",
    "\n",
    "print('Top 5 Features:')\n",
    "print(abs(feat_imp).sort_values(by=0, ascending=False).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "techie freq:  35004\n",
      "khe freq:  19411\n",
      "moff freq:  22764\n",
      "unsigned freq:  37323\n",
      "ankles freq:  1896\n"
     ]
    }
   ],
   "source": [
    "top_feat = abs(feat_imp).sort_values(by=0, ascending=False).head().index\n",
    "for feat in top_feat:\n",
    "    print(f'{feat} freq: ', vectorizer.vocabulary_[feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Word Feature Freq:  19829.0\n"
     ]
    }
   ],
   "source": [
    "print('Avg Word Feature Freq: ', np.array(list(vectorizer.vocabulary_.values())).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь и далее оценка качества будет выполняться с помощью `cross_val_score` с `cv=5` и остальными параметрами по умолчанию. Оцените среднее качество: `mean()` и стандартное отклонение `std()` по фолдамам для:\n",
    "- а) `pipeline` из `CountVectorizer()` и `LogisticRegression()`\n",
    "- б) `pipeline` из `TfidfVectorizer()` и `LogisticRegression()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy CV :  0.841\n",
      "Std Accuracy CV :  0.01677796173556255\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('feat_gen', CountVectorizer()),\n",
    "    ('model', LogisticRegression(solver='liblinear'))\n",
    "])\n",
    "\n",
    "cv_results = cross_val_score(pipeline, X=all_reviews, y=labels, n_jobs=-1, scoring='accuracy', error_score='raise')\n",
    "print('Mean Accuracy CV : ', np.mean(cv_results))\n",
    "print('Std Accuracy CV : ', np.std(cv_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy CV :  0.8210000000000001\n",
      "Std Accuracy CV :  0.004062019202317978\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('feat_gen', TfidfVectorizer()),\n",
    "    ('model', LogisticRegression(solver='liblinear'))\n",
    "])\n",
    "\n",
    "cv_results = cross_val_score(pipeline, X=all_reviews, y=labels, n_jobs=-1, scoring='accuracy', error_score='raise')\n",
    "print('Mean Accuracy CV : ', np.mean(cv_results))\n",
    "print('Std Accuracy CV : ', np.std(cv_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуйте задавать разные значения параметра `min_df` у `CountVectorizer`. \n",
    "\n",
    "Оцените качество вашего классификатора с `min_df=10` и с `min_df=50`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "min_df:  10\n",
      "Mean Accuracy CV :  0.8390000000000001\n",
      "Std Accuracy CV :  0.011895377253370336\n",
      "\n",
      "min_df:  50\n",
      "Mean Accuracy CV :  0.813\n",
      "Std Accuracy CV :  0.013453624047073712\n"
     ]
    }
   ],
   "source": [
    "min_dfs = [10, 50]\n",
    "\n",
    "for min_df in min_dfs:\n",
    "    pipeline = Pipeline([\n",
    "        ('feat_gen', CountVectorizer(min_df=min_df)),\n",
    "        ('model', LogisticRegression(solver='liblinear'))\n",
    "    ])\n",
    "    \n",
    "    print('\\nmin_df: ', min_df)\n",
    "    cv_results = cross_val_score(pipeline, X=all_reviews, y=labels, n_jobs=-1, scoring='accuracy', error_score='raise')\n",
    "    print('Mean Accuracy CV : ', np.mean(cv_results))\n",
    "    print('Std Accuracy CV : ', np.std(cv_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуйте использовать разные классификаторы после `CountVectorizer`. И vectorizer, и классификатор берите с параметрами по умолчанию. Сравните результаты для `LogisticRegression`, `LinearSVC` и `SGDClassifier`.\n",
    "\n",
    "Выпишите в ответе на соответствующий вопрос самое худшее качество из получившихся."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy CV :  0.8424999999999999\n",
      "Std Accuracy CV :  0.021794494717703363\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('feat_gen', CountVectorizer()),\n",
    "    ('model', LogisticRegression())\n",
    "])\n",
    "\n",
    "cv_results = cross_val_score(pipeline, X=all_reviews, y=labels, n_jobs=-1, scoring='accuracy', error_score='raise')\n",
    "print('Mean Accuracy CV : ', np.mean(cv_results))\n",
    "print('Std Accuracy CV : ', np.std(cv_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy CV :  0.8325000000000001\n",
      "Std Accuracy CV :  0.0162788205960997\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('feat_gen', CountVectorizer()),\n",
    "    ('model', LinearSVC())\n",
    "])\n",
    "\n",
    "cv_results = cross_val_score(pipeline, X=all_reviews, y=labels, n_jobs=-1, scoring='accuracy', error_score='raise')\n",
    "print('Mean Accuracy CV : ', np.mean(cv_results))\n",
    "print('Std Accuracy CV : ', np.std(cv_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy CV :  0.8379999999999999\n",
      "Std Accuracy CV :  0.01784656829757476\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('feat_gen', CountVectorizer()),\n",
    "    ('model', SGDClassifier())\n",
    "])\n",
    "\n",
    "cv_results = cross_val_score(pipeline, X=all_reviews, y=labels, n_jobs=-1, scoring='accuracy', error_score='raise')\n",
    "print('Mean Accuracy CV : ', np.mean(cv_results))\n",
    "print('Std Accuracy CV : ', np.std(cv_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) LogisticRegression\n",
    "2) SGDClassifier\n",
    "3) LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовьте список стоп-слов с помощью `nltk.corpus.stopwords.words('english')` посмотрите на его элементы, и передайте его в соответствующий параметр `CountVectorizer`. \n",
    "\n",
    "В `sklearn` также предусмотрен свой список английских стоп-слов - для этого нужно задать соответствующий параметр равным строке 'english'. Оцените качество классификатора в одном и другом случае и выпишете сначала качество в первом варианте, затем во втором в соответствующем вопросе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_nltk = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy CV :  0.8400000000000001\n",
      "Std Accuracy CV :  0.01129158979063624\n",
      "Mean Accuracy CV :  0.8365\n",
      "Std Accuracy CV :  0.013472193585307468\n"
     ]
    }
   ],
   "source": [
    "stops = [stop_words_nltk, 'english']\n",
    "for stop in stops:\n",
    "    pipeline = Pipeline([\n",
    "        ('feat_gen', CountVectorizer(stop_words=stop)),\n",
    "        ('model', LogisticRegression())\n",
    "    ])\n",
    "\n",
    "    cv_results = cross_val_score(pipeline, X=all_reviews, y=labels, n_jobs=-1, scoring='accuracy', error_score='raise')\n",
    "    print('Mean Accuracy CV : ', np.mean(cv_results))\n",
    "    print('Std Accuracy CV : ', np.std(cv_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуйте в `CountVectorizer` добавить к словам биграммы и измерить качество модели. А затем постройте модель на частотах буквенных n-грамм c n от 3 до 5, указав соответствующее значение параметра `ngram_range` и параметр `analyzer='char_wb'`. Полученные два числа запишите через пробел в ответе на соответствующий вопрос."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy CV :  0.764\n",
      "Std Accuracy CV :  0.008455767262643892\n"
     ]
    }
   ],
   "source": [
    "# Using bigrams\n",
    "pipeline = Pipeline([\n",
    "    ('feat_gen', CountVectorizer(stop_words=stop_words_nltk, ngram_range=(2,2))),\n",
    "    ('model', LogisticRegression())\n",
    "])\n",
    "\n",
    "cv_results = cross_val_score(pipeline, X=all_reviews, y=labels, n_jobs=-1, scoring='accuracy', error_score='raise')\n",
    "print('Mean Accuracy CV : ', np.mean(cv_results))\n",
    "print('Std Accuracy CV : ', np.std(cv_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy CV :  0.8255000000000001\n",
      "Std Accuracy CV :  0.007968688725254608\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('feat_gen', CountVectorizer(stop_words=stop_words_nltk, ngram_range=(3,5), analyzer='char_wb')),\n",
    "    ('model', LogisticRegression())\n",
    "])\n",
    "\n",
    "cv_results = cross_val_score(pipeline, X=all_reviews, y=labels, n_jobs=-1, scoring='accuracy', error_score='raise')\n",
    "print('Mean Accuracy CV : ', np.mean(cv_results))\n",
    "print('Std Accuracy CV : ', np.std(cv_results))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
